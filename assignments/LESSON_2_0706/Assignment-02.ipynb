{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments for Week-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course, we learnt what's the search problem and what's the machine leanring. In this assignment, we need you do some more practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Re-code the house price machine learning\n",
    "\n",
    "###### 1. Random Choose Method to get optimal *k* and *b*\n",
    "###### 2.Supervised Direction to get optimal *k* and *b*\n",
    "###### 3.Gradient Descent to get optimal *k* and *b*\n",
    "###### 4. Try different Loss function and learning rate. \n",
    "\n",
    "For example, you can change the loss function: $Loss = \\frac{1}{n} sum({y_i - \\hat{y_i}})^2$ to $Loss = \\frac{1}{n} sum(|{y_i - \\hat{y_i}}|)$\n",
    "\n",
    "And you can change the learning rate and observe the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1562414412237&di=8377c38d7b50c6f8d45b92ccc78dc1e7&imgtype=0&src=http%3A%2F%2Fmmbiz.qpic.cn%2Fmmbiz_jpg%2FlSyiavfm6wPgQDuDYa42IMgSkLOcPJU91RbkMibGy7VHLrhhNVLibTYk1iaLcmXKTdHc4icTDVia59QFXwqpW8cLflaw%2F640%3Fwx_fmt%3Djpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Answer following questions:\n",
    "\n",
    "\n",
    "###### 1. Why do we need machine learning methods instead of creating a complicated formula?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:自动化高效；精准"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.  Wha't's the disadvantages of `the 1st Random Choosen` methods in our course? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:因随机的计算导致耗时长，最后也不一定是最优解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Is the `2nd method supervised direction` better than 1st one?  What's the disadvantages of `the 2nd supversied directin` method? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:有方向性的解法比第一种好；缺点是方向性和步长不变导致求解的速度慢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. Why do we use `Derivative / Gredient` to fit a target function? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:快速精准求解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5. In the words 'Gredient Descent', what's the `Gredient` and what's the `Descent`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:梯度下降；梯度：对一个函数中的各个向量做偏导数，以向量的方式呈现就是梯度；梯度下降：损失函数的最小值；梯度上升：损失函数的最大值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6. What's the advantages of `the 3rd gradient descent method` compared to the previous methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:速度快，精准"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 7. Using the simple words to describe: What's the machine leanring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:给定条件让机器自动化求解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finish the search problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please using the search policy to implement an agent. This agent receives two input, one is @param start station and the other is @param destination. Your agent should give the optimal route based on Beijing Subway system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Deadline: 2019-July-13\n",
    "\n",
    ">Submit: Submit the source code and result to github. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1562414356407&di=b57814aafd215bb8b8d9d8cd37c573d6&imgtype=0&src=http%3A%2F%2Fcli.clewm.net%2Ffile%2F2015%2F03%2F24%2F174ed60082b8422ac0636cfd3efb9e7f.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataflow: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.\tGet data from web page.\n",
    "\n",
    "> a.\tGet web page source from: https://baike.baidu.com/item/%E5%8C%97%E4%BA%AC%E5%9C%B0%E9%93%81/408485\n",
    "\n",
    "> b.\tYou may need @package **requests**[https://2.python-requests.org/en/master/] page to get the response via url\n",
    "\n",
    "> c.\tYou may need save the page source to file system.\n",
    "\n",
    "> d.\tThe target of this step is to get station information of all the subway lines;\n",
    "\n",
    "> e.\tYou may need install @package beautiful soup[https://www.crummy.com/software/BeautifulSoup/bs4/doc/]  to get the url information, or just use > Regular Expression to get the url.  Our recommendation is that using the Regular Expression and BeautiflSoup both. \n",
    "\n",
    "> f.\tYou may need BFS to get all the related page url from one url. \n",
    "Question: Why do we use BFS to traverse web page (or someone said, build a web spider)?  Can DFS do this job? which is better? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.\tPreprocessing data from page source.\n",
    "\n",
    "> a.\tBased on the page source gotten from url. You may need some more preprocessing of the page. \n",
    "\n",
    "> b.\tthe Regular Expression you may need to process the text information.\n",
    "\n",
    "> c.\tYou may need @package networkx, @package matplotlib to visualize data. \n",
    "\n",
    "> d.\tYou should build a dictionary or graph which could represent the connection information of Beijing subway routes. \n",
    "\n",
    "> e.\tYou may need the defaultdict, set data structures to implement this procedure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Build the search agent\n",
    "\n",
    "> Build the search agent based on the graph we build.\n",
    "\n",
    "for example, when you run: \n",
    "\n",
    "```python\n",
    ">>> search('奥体中心', '天安门') \n",
    "```\n",
    "you need get the result: \n",
    "\n",
    "奥体中心-> A -> B -> C -> ... -> 天安门\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "北京地铁1号线\n",
      "北京地铁13号线\n",
      "北京地铁八通线\n",
      "北京地铁5号线\n",
      "北京地铁8号线\n",
      "北京地铁10号线\n",
      "北京地铁机场线\n",
      "北京地铁4号线\n",
      "北京地铁15号线\n",
      "北京地铁昌平线\n",
      "北京地铁大兴线\n",
      "北京地铁房山线\n",
      "北京地铁亦庄线\n",
      "北京地铁9号线\n",
      "北京地铁6号线\n",
      "北京地铁14号线\n",
      "北京地铁7号线\n",
      "北京地铁16号线\n",
      "北京地铁西郊线\n",
      "北京地铁S1线\n",
      "北京地铁燕房线\n",
      "北京地铁2号线\n",
      "defaultdict(<class 'dict'>, {'苹果园': ['古城', '杨庄', '金安桥'], '古城': ['八角游乐园', '苹果园'], '八角游乐园': ['八宝山', '古城'], '八宝山': ['玉泉路', '八角游乐园'], '玉泉路': ['五棵松', '八宝山'], '五棵松': ['万寿路', '玉泉路'], '万寿路': ['公主坟', '五棵松'], '公主坟': ['军事博物馆', '万寿路', '西钓鱼台', '莲花桥'], '军事博物馆': ['木樨地', '公主坟', '白堆子', '北京西站'], '木樨地': ['南礼士路', '军事博物馆'], '南礼士路': ['复兴门', '木樨地'], '复兴门': ['西单', '南礼士路', '长椿街', '阜成门'], '西单': ['天安门西', '复兴门', '宣武门', '灵境胡同'], '天安门西': ['天安门东', '西单'], '天安门东': ['王府井', '天安门西'], '王府井': ['东单', '天安门东'], '东单': ['建国门', '王府井', '灯市口', '崇文门'], '建国门': ['永安里', '东单', '朝阳门', '北京站'], '永安里': ['国贸', '建国门'], '国贸': ['大望路', '永安里', '双井', '金台夕照'], '大望路': ['四惠', '国贸', '金台路', '九龙山'], '四惠': ['四惠东', '大望路'], '四惠东': ['苹果园', '高碑店', '四惠'], '西直门': ['明光桥西', '新街口', '动物园', '车公庄', '积水潭'], '明光桥西': ['大钟寺', '西直门'], '大钟寺': ['知春路', '明光桥西'], '知春路': ['五道口', '大钟寺', '西土城', '知春里'], '五道口': ['清华东路西口', '知春路'], '清华东路西口': ['上地', '五道口', '俸伯'], '上地': ['清河', '清华东路西口'], '清河': ['西二旗', '上地'], '西二旗': ['龙泽', '清河', '昌平西山口'], '龙泽': ['回龙观', '西二旗'], '回龙观': ['霍营', '龙泽'], '霍营': ['建材城东路', '回龙观', '育新', '回龙观东大街'], '建材城东路': ['立水桥', '霍营'], '立水桥': ['北苑', '建材城东路', '天通苑南', '立水桥南'], '北苑': ['来广营西', '立水桥'], '来广营西': ['望京西', '北苑'], '望京西': ['望和桥', '来广营西', '关庄', '望京'], '望和桥': ['芍药居', '望京西'], '芍药居': ['光熙门', '望和桥', '太阳宫', '惠新西街南口'], '光熙门': ['柳芳', '芍药居'], '柳芳': ['东直门', '光熙门'], '东直门': ['西直门', '三元桥', '雍和宫', '东四十条'], '高碑店': ['传媒大学', '四惠东'], '传媒大学': ['双桥', '高碑店'], '双桥': ['管庄', '传媒大学'], '管庄': ['八里桥', '双桥'], '八里桥': ['通州北苑', '管庄'], '通州北苑': ['果园', '八里桥'], '果园': ['九棵树', '通州北苑'], '九棵树': ['梨园', '果园'], '梨园': ['临河里', '九棵树'], '临河里': ['土桥', '梨园'], '土桥': ['四惠'], '宋家庄': ['刘家窑', '石榴庄', '成寿寺', '肖村'], '刘家窑': ['蒲黄榆', '宋家庄'], '蒲黄榆': ['天坛东门', '刘家窑', '方庄', '景泰'], '天坛东门': ['磁器口', '蒲黄榆'], '磁器口': ['崇文门', '天坛东门', '广渠门内', '桥湾'], '崇文门': ['东单', '磁器口', '北京站', '前门'], '灯市口': ['东四', '东单'], '东四': ['张自忠路', '灯市口', '朝阳门', '南锣鼓巷'], '张自忠路': ['北新桥', '东四'], '北新桥': ['雍和宫', '张自忠路'], '雍和宫': ['和平里北街', '北新桥', '安定门', '东直门'], '和平里北街': ['和平西桥', '雍和宫'], '和平西桥': ['惠新西街南口', '和平里北街'], '惠新西街南口': ['惠新西街北口', '和平西桥', '芍药居', '安贞门'], '惠新西街北口': ['大屯路东', '惠新西街南口'], '大屯路东': ['北苑路北', '惠新西街北口', '安立路', '关庄'], '北苑路北': ['立水桥南', '大屯路东'], '立水桥南': ['立水桥', '北苑路北'], '天通苑南': ['天通苑', '立水桥'], '天通苑': ['天通苑北', '天通苑南'], '天通苑北': ['宋家庄'], '朱辛庄': ['育知路', '生命科学园', '巩华城'], '育知路': ['平西府', '朱辛庄'], '平西府': ['回龙观东大街', '育知路'], '回龙观东大街': ['霍营', '平西府'], '育新': ['西小口', '霍营'], '西小口': ['永泰庄', '育新'], '永泰庄': ['林萃桥', '西小口'], '林萃桥': ['森林公园南门', '永泰庄'], '森林公园南门': ['奥林匹克公园', '林萃桥'], '奥林匹克公园': ['奥体中心', '森林公园南门', '北沙滩', '安立路'], '奥体中心': ['北土城', '奥林匹克公园'], '北土城': ['安华桥', '奥体中心', '安贞门', '健德门'], '安华桥': ['安德里北街', '北土城'], '安德里北街': ['鼓楼大街', '安华桥'], '鼓楼大街': ['什刹海', '安德里北街', '积水潭', '安定门'], '什刹海': ['南锣鼓巷', '鼓楼大街'], '南锣鼓巷': ['中国美术馆', '什刹海', '东四', '北海北'], '中国美术馆': ['朱辛庄'], '瀛海': ['德茂'], '德茂': ['五福堂', '瀛海'], '五福堂': ['火箭万源', '德茂'], '火箭万源': ['东高地', '五福堂'], '东高地': ['和义', '火箭万源'], '和义': ['大红门南', '东高地'], '大红门南': ['大红门', '和义'], '大红门': ['海户屯', '大红门南', '角门东', '石榴庄'], '海户屯': ['木樨园', '大红门'], '木樨园': ['永定门外', '海户屯'], '永定门外': ['天桥', '木樨园', '景泰', '北京南站'], '天桥': ['珠市口', '永定门外'], '珠市口': ['瀛海', '桥湾', '虎坊桥'], '巴沟': ['苏州街', '火器营', '颐和园西门'], '苏州街': ['海淀黄庄', '巴沟'], '海淀黄庄': ['知春里', '苏州街', '人民大学', '中关村'], '知春里': ['知春路', '海淀黄庄'], '西土城': ['牡丹园', '知春路'], '牡丹园': ['健德门', '西土城'], '健德门': ['北土城', '牡丹园'], '安贞门': ['惠新西街南口', '北土城'], '太阳宫': ['三元桥', '芍药居'], '三元桥': ['亮马桥', '太阳宫', '3号航站楼', '东直门'], '亮马桥': ['农业展览馆', '三元桥'], '农业展览馆': ['团结湖', '亮马桥'], '团结湖': ['呼家楼', '农业展览馆'], '呼家楼': ['金台夕照', '团结湖', '金台路', '东大桥'], '金台夕照': ['国贸', '呼家楼'], '双井': ['劲松', '国贸', '九龙山', '广渠门外'], '劲松': ['潘家园', '双井'], '潘家园': ['十里河', '劲松'], '十里河': ['分钟寺', '潘家园', '北工大西门', '方庄'], '分钟寺': ['成寿寺', '十里河'], '成寿寺': ['宋家庄', '分钟寺'], '石榴庄': ['大红门', '宋家庄'], '角门东': ['角门西', '大红门'], '角门西': ['草桥', '角门东', '公益西桥', '马家堡'], '草桥': ['纪家庙', '角门西'], '纪家庙': ['首经贸', '草桥'], '首经贸': ['丰台', '纪家庙'], '丰台': ['泥洼', '首经贸'], '泥洼': ['西局', '丰台'], '西局': ['六里桥', '泥洼', '张郭庄'], '六里桥': ['莲花桥', '西局', '六里桥东', '七里庄'], '莲花桥': ['公主坟', '六里桥'], '西钓鱼台': ['慈寿寺', '公主坟'], '慈寿寺': ['车道沟', '西钓鱼台', '花园桥', '海淀五路居'], '车道沟': ['长春桥', '慈寿寺'], '长春桥': ['火器营', '车道沟'], '火器营': ['长春桥', '巴沟'], '3号航站楼': ['2号航站楼', '三元桥'], '2号航站楼': ['东直门'], '往公益西桥方向': ['车'], '车': ['安河桥北', '往公益西桥方向'], '安河桥北': ['北宫门', '车'], '北宫门': ['西苑', '安河桥北'], '西苑': ['圆明园', '北宫门', '农大南路'], '圆明园': ['北京大学东门', '西苑'], '北京大学东门': ['中关村', '圆明园'], '中关村': ['海淀黄庄', '北京大学东门'], '人民大学': ['魏公村', '海淀黄庄'], '魏公村': ['国家图书馆', '人民大学'], '国家图书馆': ['动物园', '魏公村', '郭公庄'], '动物园': ['西直门', '国家图书馆'], '新街口': ['平安里', '西直门'], '平安里': ['西四', '新街口', '北海北', '车公庄'], '西四': ['灵境胡同', '平安里'], '灵境胡同': ['西单', '西四'], '宣武门': ['菜市口', '西单', '和平门', '长椿街'], '菜市口': ['陶然亭', '宣武门', '虎坊桥', '广安门内'], '陶然亭': ['北京南站', '菜市口'], '北京南站': ['马家堡', '陶然亭', '永定门外'], '马家堡': ['角门西', '北京南站'], '公益西桥': ['往公益西桥方向', '新宫'], '俸伯': ['顺义'], '顺义': ['石门', '俸伯'], '石门': ['南法信', '顺义'], '南法信': ['后沙峪', '石门'], '后沙峪': ['花梨坎', '南法信'], '花梨坎': ['国展', '后沙峪'], '国展': ['孙河', '花梨坎'], '孙河': ['马泉营', '国展'], '马泉营': ['崔各庄', '孙河'], '崔各庄': ['望京东', '马泉营'], '望京东': ['望京', '崔各庄'], '望京': ['望京西', '望京东', '东湖渠', '阜通'], '关庄': ['大屯路东', '望京西'], '安立路': ['奥林匹克公园', '大屯路东'], '北沙滩': ['六道口', '奥林匹克公园'], '六道口': ['清华东路西口', '北沙滩'], '昌平西山口': ['十三陵景区'], '十三陵景区': ['昌平', '昌平西山口'], '昌平': ['昌平东关', '十三陵景区'], '昌平东关': ['北邵洼', '昌平'], '北邵洼': ['南邵', '昌平东关'], '南邵': ['沙河高教园', '北邵洼'], '沙河高教园': ['沙河', '南邵'], '沙河': ['巩华城', '沙河高教园'], '巩华城': ['朱辛庄', '沙河'], '生命科学园': ['西二旗', '朱辛庄'], '新宫': ['西红门', '公益西桥'], '西红门': ['高米店北', '新宫'], '高米店北': ['高米店南', '西红门'], '高米店南': ['枣园', '高米店北'], '枣园': ['清源路', '高米店南'], '清源路': ['黄村西大街', '枣园'], '黄村西大街': ['黄村火车站', '清源路'], '黄村火车站': ['义和庄', '黄村西大街'], '义和庄': ['生物医药基地', '黄村火车站'], '生物医药基地': ['公益西桥'], '郭公庄': ['大葆台', '丰台科技园'], '大葆台': ['稻田', '郭公庄'], '稻田': ['长阳', '大葆台'], '长阳': ['篱笆房', '稻田'], '篱笆房': ['广阳城', '长阳'], '广阳城': ['良乡大学城北', '篱笆房'], '良乡大学城北': ['良乡大学城', '广阳城'], '良乡大学城': ['良乡大学城西', '良乡大学城北'], '良乡大学城西': ['良乡南关', '良乡大学城'], '良乡南关': ['苏庄', '良乡大学城西'], '苏庄': ['阎村东', '良乡南关'], '阎村东': ['郭公庄', '紫草坞'], '肖村': ['小红门', '宋家庄'], '小红门': ['旧宫', '肖村'], '旧宫': ['亦庄桥', '小红门'], '亦庄桥': ['亦庄文化园', '旧宫'], '亦庄文化园': ['万源街', '亦庄桥'], '万源街': ['荣京东街', '亦庄文化园'], '荣京东街': ['荣昌东街', '万源街'], '荣昌东街': ['同济南路', '荣京东街'], '同济南路': ['经海路', '荣昌东街'], '经海路': ['次渠南', '同济南路'], '次渠南': ['次渠', '经海路'], '次渠': ['亦庄火车站', '次渠南'], '亦庄火车站': ['宋家庄'], '丰台科技园': ['科怡路', '郭公庄'], '科怡路': ['丰台南路', '丰台科技园'], '丰台南路': ['丰台东大街', '科怡路'], '丰台东大街': ['七里庄', '丰台南路'], '七里庄': ['六里桥', '丰台东大街', '西局', '大井'], '六里桥东': ['北京西站', '六里桥'], '北京西站': ['军事博物馆', '六里桥东', '湾子'], '白堆子': ['白石桥南', '军事博物馆'], '白石桥南': ['国家图书馆', '白堆子', '车公庄西', '花园桥'], '金安桥': ['苹果园', '四道桥'], '杨庄': ['西黄村', '苹果园'], '西黄村': ['廖公庄', '杨庄'], '廖公庄': ['田村', '西黄村'], '田村': ['海淀五路居', '廖公庄'], '海淀五路居': ['慈寿寺', '田村'], '花园桥': ['白石桥南', '慈寿寺'], '车公庄西': ['车公庄', '白石桥南'], '车公庄': ['平安里', '车公庄西', '阜成门', '西直门'], '北海北': ['南锣鼓巷', '平安里'], '朝阳门': ['东大桥', '东四', '东四十条', '建国门'], '东大桥': ['呼家楼', '朝阳门'], '金台路': ['十里堡', '呼家楼', '朝阳公园', '大望路'], '十里堡': ['青年路', '金台路'], '青年路': ['褡裢坡', '十里堡'], '褡裢坡': ['黄渠', '青年路'], '黄渠': ['常营', '褡裢坡'], '常营': ['草房', '黄渠'], '草房': ['物资学院路', '常营'], '物资学院路': ['通州北关', '草房'], '通州北关': ['通运门', '物资学院路'], '通运门': ['北运河西', '通州北关'], '北运河西': ['北运河东', '通运门'], '北运河东': ['郝家府', '北运河西'], '郝家府': ['东夏园', '北运河东'], '东夏园': ['潞城', '郝家府'], '潞城': ['金安桥'], '张郭庄': ['园博园'], '园博园': ['大瓦窑', '张郭庄'], '大瓦窑': ['郭庄子', '园博园'], '郭庄子': ['大井', '大瓦窑'], '大井': ['七里庄', '郭庄子'], '景泰': ['蒲黄榆', '永定门外'], '方庄': ['十里河', '蒲黄榆'], '北工大西门': ['九龙山', '十里河'], '九龙山': ['大望路', '北工大西门', '大郊亭', '双井'], '朝阳公园': ['枣营', '金台路'], '枣营': ['东风北桥', '朝阳公园'], '东风北桥': ['将台', '枣营'], '将台': ['望京南', '东风北桥'], '望京南': ['阜通', '将台'], '阜通': ['望京', '望京南'], '东湖渠': ['来广营', '望京'], '来广营': ['善各庄', '东湖渠'], '善各庄': ['北京南站'], '湾子': ['达官营', '北京西站'], '达官营': ['广安门内', '湾子'], '广安门内': ['菜市口', '达官营'], '虎坊桥': ['珠市口', '菜市口'], '桥湾': ['磁器口', '珠市口'], '广渠门内': ['广渠门外', '磁器口'], '广渠门外': ['双井', '广渠门内'], '大郊亭': ['百子湾', '九龙山'], '百子湾': ['化工', '大郊亭'], '化工': ['南楼梓庄', '百子湾'], '南楼梓庄': ['欢乐谷景区', '化工'], '欢乐谷景区': ['垡头', '南楼梓庄'], '垡头': ['双合', '欢乐谷景区'], '双合': ['焦化厂', '垡头'], '焦化厂': ['北京西站'], '农大南路': ['马连洼', '西苑'], '马连洼': ['西北旺', '农大南路'], '西北旺': ['永丰南', '马连洼'], '永丰南': ['永丰', '西北旺'], '永丰': ['屯佃', '永丰南'], '屯佃': ['稻香湖路', '永丰'], '稻香湖路': ['温阳路', '屯佃'], '温阳路': ['北安河', '稻香湖路'], '北安河': ['西苑'], '颐和园西门': ['茶棚', '巴沟'], '茶棚': ['万安', '颐和园西门'], '万安': ['植物园', '茶棚'], '植物园': ['香山', '万安'], '香山': ['巴沟'], '四道桥': ['桥户营', '金安桥'], '桥户营': ['上岸', '四道桥'], '上岸': ['栗园庄', '桥户营'], '栗园庄': ['小园', '上岸'], '小园': ['石厂', '栗园庄'], '石厂': ['苹果园'], '紫草坞': ['阎村', '阎村东'], '阎村': ['星城', '紫草坞'], '星城': ['大石河东', '阎村'], '大石河东': ['马各庄', '星城'], '马各庄': ['饶乐府', '大石河东'], '饶乐府': ['房山城关', '马各庄'], '房山城关': ['燕山', '饶乐府'], '燕山': ['老城区', '房山城关'], '老城区': ['顾册', '燕山'], '顾册': ['周口店镇', '老城区'], '周口店镇': ['阎村东'], '阜成门': ['复兴门', '车公庄'], '长椿街': ['宣武门', '复兴门'], '和平门': ['前门', '宣武门'], '前门': ['崇文门', '和平门'], '北京站': ['建国门', '崇文门'], '东四十条': ['东直门', '朝阳门'], '安定门': ['鼓楼大街', '雍和宫'], '积水潭': ['鼓楼大街', '西直门']})\n",
      "1111111111111111111111111111111\n",
      "['西单', '灵境胡同', '西四', '平安里', '北海北', '南锣鼓巷', '中国美术馆']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, re, urllib, time\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def requests_get_all_contents(url):\n",
    "    requests_get_all = requests.get(url, headers=headers)\n",
    "    #print(requests_get_all.status_code)\n",
    "    requests_get_all.encoding = requests_get_all.apparent_encoding\n",
    "    return requests_get_all\n",
    "\n",
    "def write_in_text(content, file_name):\n",
    "    with open(file_name, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(content)\n",
    "\n",
    "def merge_new_sites(new_site, all_sites):\n",
    "    for k in new_site:\n",
    "        if k in all_sites:\n",
    "            all_sites[k]['nabours'] += new_site[k]['nabours']\n",
    "            all_sites[k]['line'] += new_site[k]['line']\n",
    "        else:\n",
    "            all_sites.update(new_site)\n",
    "    return(all_sites)\n",
    "\n",
    "def  find_string_key_word_tables(table_key_words, soup):\n",
    "    for i in table_key_words:\n",
    "        key_word_all_info = soup.find_all(string = re.compile(\".*\" + i + \"$\"))\n",
    "        for r in key_word_all_info:\n",
    "            if r.find_parents('table'):  # 14号线参考资料里面有个  列车时刻表 的祖节点无table，上面是有正确信息的\n",
    "                return i\n",
    "    return False\n",
    "\n",
    "def not_inclued(list, string):\n",
    "    for each in list:\n",
    "        if each in string:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def add_one_site_in_one_line(all_sites_in_one_line, remain_list, string):\n",
    "    if not_inclued(remain_list, string):\n",
    "        all_sites_in_one_line.append(string.strip('站'))\n",
    "    else:\n",
    "        all_sites_in_one_line.append(string)\n",
    "    return all_sites_in_one_line\n",
    "\n",
    "def sites_search_shikebiao_shijianbiao(all_sites_in_one_line, line_site_table):\n",
    "    first_column = line_site_table.find_all('tr', )\n",
    "    for each in first_column:\n",
    "        if each.next_element.string == None:\n",
    "            continue\n",
    "        if not_inclued(remove_list, each.next_element.string):\n",
    "            all_sites_in_one_line = add_one_site_in_one_line(all_sites_in_one_line, remain_list, each.next_element.string)\n",
    "    return all_sites_in_one_line\n",
    "\n",
    "def sites_search_jianjuxinxi(all_sites_in_one_line, line_site_table):\n",
    "    first_column = line_site_table.find_all('tr', )\n",
    "    for each in first_column:\n",
    "        if each.next_element.string == None:\n",
    "            continue\n",
    "        if not_inclued(remove_list, each.next_element.string):\n",
    "            site = each.next_element.string.split('——')[0]\n",
    "            all_sites_in_one_line = add_one_site_in_one_line(all_sites_in_one_line, remain_list, site)\n",
    "    return all_sites_in_one_line\n",
    "\n",
    "def sites_search_chezhanmingcheng(all_sites_in_one_line, line_site_table):\n",
    "    first_column = line_site_table.find_all('tr', )\n",
    "    for each in first_column:\n",
    "        site = each.find_all(string = re.compile('.*站$'))\n",
    "        if site == []:\n",
    "            continue\n",
    "        else:\n",
    "            all_sites_in_one_line =add_one_site_in_one_line(all_sites_in_one_line, remain_list, site[0])\n",
    "    return all_sites_in_one_line\n",
    "\n",
    "def search_all_sites_in_one_line(k, v, single_line_soup):\n",
    "    line_site_tables = single_line_soup.find_all(string=re.compile(\".*\" + v['search_table'] + \"$\"))\n",
    "    #print(line_site_tables)\n",
    "    if v['search_table'] == '车时刻表' or v['search_table'] == '车时间':  #时刻表可能有分段的，另外两种情况没有\n",
    "        for t in line_site_tables:\n",
    "            all_sites_in_one_line = []\n",
    "            if not t.find_parents('table'):  #14号线参考资料里面有个  列车时刻表 祖节点无table\n",
    "                continue\n",
    "            line_site_table = t.find_parents('table')[0]\n",
    "            all_sites_in_one_line = sites_search_shikebiao_shijianbiao(all_sites_in_one_line, line_site_table)\n",
    "            add_new_site(all_sites_in_one_line, k, v)\n",
    "\n",
    "    if v['search_table'] == '间距信息统计表':\n",
    "        all_sites_in_one_line = []\n",
    "        all_sites_in_one_line = sites_search_jianjuxinxi(all_sites_in_one_line, line_site_tables[0].find_parents('table')[0])\n",
    "        add_new_site(all_sites_in_one_line, k, v)\n",
    "    if v['search_table'] == '车站名称':\n",
    "        all_sites_in_one_line = []\n",
    "        all_sites_in_one_line = sites_search_chezhanmingcheng(all_sites_in_one_line, line_site_tables[0].find_parents('table')[0])\n",
    "        add_new_site(all_sites_in_one_line, k, v)\n",
    "\n",
    "    #print(len(all_sites_in_one_line))\n",
    "    #print (False if  all_sites_in_one_line == [] else True)\n",
    "    return (False if  all_sites_in_one_line == [] else True)\n",
    "\n",
    "\n",
    "def add_new_site(all_sites_in_one_line, line_parameters_k, line_parameters_v ):\n",
    "    for i in range(len(all_sites_in_one_line)):\n",
    "        new_site_dict = defaultdict(dict)\n",
    "        new_site_dict[all_sites_in_one_line[i]]['name'] = all_sites_in_one_line[i]\n",
    "        new_site_dict[all_sites_in_one_line[i]]['line'] = [line_parameters_k]\n",
    "        if i == 0 and  line_parameters_v['loop'] == True:\n",
    "            new_site_dict[all_sites_in_one_line[i]]['nabours'] = [all_sites_in_one_line[i + 1]] + [all_sites_in_one_line[-1]]\n",
    "        elif i == 0:\n",
    "            new_site_dict[all_sites_in_one_line[i]]['nabours'] = [all_sites_in_one_line[i + 1]]\n",
    "        elif i == len(all_sites_in_one_line) -1 and  line_parameters_v['loop'] == True:\n",
    "            new_site_dict[all_sites_in_one_line[i]]['nabours'] = [all_sites_in_one_line[i - 1]] + [all_sites_in_one_line[0]]\n",
    "        elif i == len(all_sites_in_one_line) -1:\n",
    "            new_site_dict[all_sites_in_one_line[i]]['nabours'] = [all_sites_in_one_line[i - i]]\n",
    "        else:\n",
    "            new_site_dict[all_sites_in_one_line[i]]['nabours'] = [all_sites_in_one_line[i + 1]] + [all_sites_in_one_line[i - 1]]\n",
    "        merge_new_sites(new_site_dict, rail_way_graph)\n",
    "\n",
    "def init_line_paramaters():\n",
    "    url_prefix = 'https://baike.baidu.com'\n",
    "    all_line_list = soup.find_all('a', href=re.compile(\"^/item/\" + urllib.request.quote('北京地铁') + \".*\" + \"%BA%BF$\"),string=re.compile(\"北京地铁.*\"))\n",
    "    for i in all_line_list:\n",
    "        if not (i.string in line_paramaters):\n",
    "            line_paramaters[i.string]['name'] = i.string\n",
    "            line_paramaters[i.string]['url'] = url_prefix + urllib.request.unquote(i['href'])\n",
    "            line_paramaters[i.string]['loop'] = False\n",
    "            line_paramaters[i.string]['search_table'] = False\n",
    "\n",
    "\n",
    "def remove_duplication(list):\n",
    "    lis = []\n",
    "    for i in list:\n",
    "        if i not in lis:\n",
    "            lis.append(i)\n",
    "    return lis\n",
    "\n",
    "def refresh_rail_way_graph():\n",
    "    for k, v in rail_way_graph.items():\n",
    "        v['nabours'] = remove_duplication(v['nabours'])\n",
    "        v['line'] = remove_duplication(v['line'])\n",
    "\n",
    "        city_connection[k] = v['nabours']\n",
    "    return city_connection\n",
    "\n",
    "\n",
    "\n",
    "def search(start, destination, connection_grpah, sort_candidate):\n",
    "    pathes = [[start]]\n",
    "\n",
    "    visitied = set()\n",
    "\n",
    "    while pathes:  # if we find existing pathes\n",
    "        path = pathes.pop(0)\n",
    "        froninter = path[-1]\n",
    "\n",
    "        if froninter in visitied: continue\n",
    "\n",
    "        successors = connection_grpah[froninter]\n",
    "        for city in successors:\n",
    "            if city in path: continue  # eliminate loop\n",
    "            new_path = path + [city]\n",
    "            pathes.append(new_path)\n",
    "            if city == destination:\n",
    "                return new_path\n",
    "        visitied.add(froninter)\n",
    "        pathes = sort_candidate(pathes)  # 我们可以加一个排序函数 对我们的搜索策略进行控制\n",
    "    print(pathes)\n",
    "\n",
    "def transfer_stations_first(pathes):\n",
    "    return sorted(pathes, key=len)\n",
    "\n",
    "def transfer_as_less_as_possible(pathes):\n",
    "    return sorted(pathes, key=len, reverse=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    url = 'https://baike.baidu.com/item/%E5%8C%97%E4%BA%AC%E5%9C%B0%E9%93%81/408485?fr=aladdin'\n",
    "    headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 SE 2.X MetaSr 1.0',\n",
    "    }\n",
    "\n",
    "    requests_get_base_all = requests_get_all_contents(url)\n",
    "    soup = BeautifulSoup(requests_get_base_all.text, 'html.parser')\n",
    "\n",
    "    line_paramaters = defaultdict(dict)\n",
    "    rail_way_graph = defaultdict(dict)\n",
    "    city_connection = defaultdict(dict)\n",
    "\n",
    "    init_line_paramaters()\n",
    "    # line_paramaters = defaultdict(dict)\n",
    "    # line_paramaters.update({'北京地铁1号线': {'name': '北京地铁1号线', 'url': 'https://baike.baidu.com/item/北京地铁1号线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁13号线': {'name': '北京地铁13号线', 'url': 'https://baike.baidu.com/item/北京地铁13号线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁八通线': {'name': '北京地铁八通线', 'url': 'https://baike.baidu.com/item/北京地铁八通线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁5号线': {'name': '北京地铁5号线', 'url': 'https://baike.baidu.com/item/北京地铁5号线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁8号线': {'name': '北京地铁8号线', 'url': 'https://baike.baidu.com/item/北京地铁8号线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁10号线': {'name': '北京地铁10号线', 'url': 'https://baike.baidu.com/item/北京地铁10号线', 'loop': True, 'search_table': '车时刻表'}, '北京地铁机场线': {'name': '北京地铁机场线', 'url': 'https://baike.baidu.com/item/北京地铁机场线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁4号线': {'name': '北京地铁4号线', 'url': 'https://baike.baidu.com/item/北京地铁4号线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁15号线': {'name': '北京地铁15号线', 'url': 'https://baike.baidu.com/item/北京地铁15号线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁昌平线': {'name': '北京地铁昌平线', 'url': 'https://baike.baidu.com/item/北京地铁昌平线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁大兴线': {'name': '北京地铁大兴线', 'url': 'https://baike.baidu.com/item/北京地铁大兴线', 'loop': False, 'search_table': '间距信息统计表'}, '北京地铁房山线': {'name': '北京地铁房山线', 'url': 'https://baike.baidu.com/item/北京地铁房山线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁亦庄线': {'name': '北京地铁亦庄线', 'url': 'https://baike.baidu.com/item/北京地铁亦庄线', 'loop': False, 'search_table': '车站名称'}, '北京地铁9号线': {'name': '北京地铁9号线', 'url': 'https://baike.baidu.com/item/北京地铁9号线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁6号线': {'name': '北京地铁6号线', 'url': 'https://baike.baidu.com/item/北京地铁6号线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁14号线': {'name': '北京地铁14号线', 'url': 'https://baike.baidu.com/item/北京地铁14号线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁7号线': {'name': '北京地铁7号线', 'url': 'https://baike.baidu.com/item/北京地铁7号线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁16号线': {'name': '北京地铁16号线', 'url': 'https://baike.baidu.com/item/北京地铁16号线', 'loop': False, 'search_table': '车时间'}, '北京地铁西郊线': {'name': '北京地铁西郊线', 'url': 'https://baike.baidu.com/item/北京地铁西郊线', 'loop': False, 'search_table': '车站名称'}, '北京地铁S1线': {'name': '北京地铁S1线', 'url': 'https://baike.baidu.com/item/北京地铁S1线', 'loop': False, 'search_table': '车时刻表'}, '北京地铁燕房线': {'name': '北京地铁燕房线', 'url': 'https://baike.baidu.com/item/北京地铁燕房线', 'loop': False, 'search_table': '车站名称'}, '北京地铁2号线': {'name': '北京地铁2号线', 'url': 'https://baike.baidu.com/item/北京地铁2号线', 'loop': True, 'search_table': '间距信息统计表'}})\n",
    "    #line_paramaters={'北京地铁燕房线': {'name': '北京地铁燕房线', 'url': 'https://baike.baidu.com/item/北京地铁燕房线', 'loop': False, 'search_table': '车站名称'}}\n",
    "\n",
    "    table_key_words = ['车时刻表', '间距信息统计表', '车时间', '车站名称']\n",
    "    remove_list = ['时刻表', '时间表', '车站名称', '【注】', '首车时间', '备注', '下行', '上行', '时间', '全程', '终到车站']\n",
    "    remain_list = ['火车站', '北京站', '北京西站', '北京南站',]\n",
    "\n",
    "\n",
    "\n",
    "    ct = 0\n",
    "    for k, v in line_paramaters.items():\n",
    "        # if ct == 2:\n",
    "        #    break\n",
    "        #采用网页爬取的数据\n",
    "        single_line = BeautifulSoup(requests_get_all_contents(v['url']).text, 'html.parser')\n",
    "\n",
    "        '''\n",
    "        # 采用已经下载好的txt文件读取\n",
    "        #file_name = str(v['name']) + '.txt'\n",
    "        #write_in_text(requests_get_each_line_all.text, file_name)\n",
    "        file_name = k + '.txt'  \n",
    "        single_line = BeautifulSoup(open(file_name, 'r', encoding='utf-8'), 'html.parser')  # 采用已经下载好的txt文件读取\n",
    "        '''\n",
    "\n",
    "\n",
    "        if (single_line.find_all(string=re.compile(\".*环线地铁\")) or single_line.find_all(string=re.compile(\".*环形地铁\"))):\n",
    "            v['loop'] = True\n",
    "\n",
    "        v['search_table'] = find_string_key_word_tables(table_key_words, single_line)\n",
    "        print(k)\n",
    "        # print(k, v['search_table'])\n",
    "        search_all_sites_in_one_line(k, v, single_line)\n",
    "\n",
    "        # ct += 1\n",
    "    # print(line_paramaters)\n",
    "\n",
    "    refresh_rail_way_graph()\n",
    "\n",
    "    print(city_connection)\n",
    "\n",
    "    simple_connection_info = defaultdict(list)\n",
    "    simple_connection_info.update(city_connection)\n",
    "\n",
    "    \n",
    "print(1111111111111111111111111111111)\n",
    "print(search('西单', '中国美术馆', simple_connection_info, sort_candidate=transfer_as_less_as_possible))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （Optional）Create different policies for transfer system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下部门为可选部分，请酌情完成。 并不要求全部同学完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As much as you can to use the already implemented search agent. You just need to define the **is_goal()**, **get_successor()**, **strategy()** three functions. \n",
    "\n",
    "> a.\tDefine different policies for transfer system. \n",
    "\n",
    "> b.\tSuch as Shortest Path Priority（路程最短优先）, Minimum Transfer Priority(最少换乘优先), Comprehensive Priority(综合优先)\n",
    "\n",
    "> c.\tImplement Continuous transfer. Based on the Agent you implemented, please add this feature: Besides the @param start and @param destination two stations, add some more stations, we called @param by_way, it means, our path should from the start and end, but also include the  @param by_way stations. \n",
    "\n",
    "e.g \n",
    "```\n",
    "1. Input:  start=A,  destination=B, by_way=[C] \n",
    "    Output: [A, … .., C, …. B]\n",
    "2. Input: start=A, destination=B, by_way=[C, D, E]\n",
    "    Output: [A … C … E … D … B]  \n",
    "    # based on your policy, the E station could be reached firstly. \n",
    "![image.png](attachment:image.png)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.\tTest your result with commercial applications. \n",
    "\n",
    "将你的结果和高德地图或者百度地图进行比较，如果有不同，请分析原因\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "恭喜，完成本次课程，你对常用的人工智能方法以及有一定的了解了。基于规则的，基于概率模型的，基于搜索的，基于机器学习的。 可以说，我们现在通常见到的方法都能够归属到这几类方法中。 这就是**人工智能**，并没有很难是吧？ 继续加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1562415163815&di=4b29a2a863a8285212033760f288ed7a&imgtype=0&src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fimages%2F20180710%2F8704194a1d7f46a383ddc29d40c9bca5.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
